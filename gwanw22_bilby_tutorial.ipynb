{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e32adb6",
   "metadata": {},
   "source": [
    "### GWANW 2022 Bilby tutorial\n",
    "\n",
    "This notebook walks you through configuring and running a GW parameter estimation job using the Bayesian inference package `Bilby`. This tutorial is based on this example, which looked at a different event: https://git.ligo.org/lscsoft/bilby/blob/master/examples/gw_examples/data_examples/GW150914.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440524f7",
   "metadata": {},
   "source": [
    "First we'll make sure we have installed the required Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install lalsuite gwosc gwpy bilby ipywidgets\n",
    "\n",
    "import math\n",
    "import bilby\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from gwosc import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14994a1e",
   "metadata": {},
   "source": [
    "For this tutorial we'll analyze one of the more notable events from the last observing run (O3), GW190521. This signal originated from a binary system of two black holes with masses of approximately 85 and 65 Msun, which merged to form a 142 Msun remnant black hole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d34cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trigger time of the event\n",
    "trigger_time = datasets.event_gps(\"GW190521\")\n",
    "\n",
    "# Analyze 4s of data around the trigger time\n",
    "seglen = 4\n",
    "post_trigger = 2\n",
    "end_time = trigger_time + post_trigger\n",
    "start_time = end_time - seglen\n",
    "\n",
    "# Frequency band\n",
    "flow = 11\n",
    "fhigh = 512\n",
    "\n",
    "# Options for PSD calculation\n",
    "psd_seglen = 32 * seglen\n",
    "psd_end_time = start_time\n",
    "psd_start_time = start_time - psd_seglen\n",
    "roll_off = 0.2\n",
    "overlap = 0\n",
    "\n",
    "# Detector list\n",
    "detectors = [\"H1\", \"L1\", \"V1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71cd5b",
   "metadata": {},
   "source": [
    "Next we fetch the strain data to be analyzed. We can do this using GWPy (see Adrian's tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifo_list = bilby.gw.detector.InterferometerList([])\n",
    "for det in detectors:\n",
    "    print(f\"Fetching data for {det}\")\n",
    "    strain_data = TimeSeries.fetch_open_data(det, start_time, end_time)\n",
    "    \n",
    "    # Insert data into bilby interferometer class\n",
    "    ifo = bilby.gw.detector.get_empty_interferometer(det)\n",
    "    ifo.strain_data.set_from_gwpy_timeseries(strain_data)\n",
    "    \n",
    "    # Calculate the PSD. There is more than one way of doing this. The method shown\n",
    "    # here involves looking at a long stretch of data before the analysis segment,\n",
    "    # splitting it into several chunks, taking the spectrum of each and averaging\n",
    "    # over all segments.\n",
    "    psd_data = TimeSeries.fetch_open_data(det, psd_start_time, psd_end_time)\n",
    "    psd_alpha = 2 * roll_off / seglen\n",
    "    psd = psd_data.psd(\n",
    "        fftlength=seglen, overlap=overlap, window=(\"tukey\", psd_alpha), method=\"median\")\n",
    "    \n",
    "    # Assign the PSD to the detector\n",
    "    ifo.power_spectral_density = bilby.gw.detector.PowerSpectralDensity(\n",
    "        frequency_array=psd.frequencies.value, psd_array=psd.value)\n",
    "    \n",
    "    ifo.maximum_frequency = fhigh\n",
    "    ifo.minimum_frequency = flow\n",
    "    ifo_list.append(ifo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57477e43",
   "metadata": {},
   "source": [
    "Set the priors. `Bilby` includes several prior distributions that we can use, or we can also define our own.\n",
    "\n",
    "For this example, we first load the default BBH priors, and then tailor the ranges to this particular event. In the interest of time, we will run a \"minimal\" example by fixing most of the parameters and sampling in just a few, but in actual analyses we usually allow all parameters to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = bilby.gw.prior.BBHPriorDict()\n",
    "\n",
    "# Sample in chirp mass and mass ratio with\n",
    "# priors that give uniform distributions in the component masses\n",
    "priors.pop(\"mass_1\")\n",
    "priors.pop(\"mass_2\")\n",
    "priors[\"chirp_mass\"] = bilby.gw.prior.UniformInComponentsChirpMass(\n",
    "    minimum=70, maximum=180, name=\"chirp_mass\", latex_label=r\"$\\mathcal{M}$\")\n",
    "priors[\"mass_ratio\"] = bilby.gw.prior.UniformInComponentsMassRatio(\n",
    "    minimum=0.1, maximum=1, name=\"mass_ratio\", latex_label=r\"$q$\")\n",
    "\n",
    "# Luminosity distance prior is uniform in comoving source-frame volume\n",
    "priors[\"luminosity_distance\"] = bilby.gw.prior.UniformSourceFrame(\n",
    "    minimum=1e2, maximum=1e5, name=\"luminosity_distance\", latex_label=r\"$d_L$\", unit=\"Mpc\")\n",
    "\n",
    "# Set time prior to be +/- 0.1s around the trigger time\n",
    "priors[\"geocent_time\"] = bilby.core.prior.Uniform(\n",
    "    minimum=trigger_time - 0.1, maximum=trigger_time + 0.1, name=\"geocent_time\", latex_label=r\"$t_{\\rm c}$\")\n",
    "\n",
    "# Fix the remaining parameters to some appropriate \n",
    "priors[\"a_1\"] = 0.4\n",
    "priors[\"a_2\"] = 0.42\n",
    "priors[\"tilt_1\"] = 0\n",
    "priors[\"tilt_2\"] = math.pi\n",
    "priors[\"phi_12\"] = 0\n",
    "priors[\"phi_jl\"] = 0\n",
    "priors[\"psi\"] = 3.13\n",
    "priors[\"ra\"] = 3.37\n",
    "priors[\"dec\"] = 0.46\n",
    "priors[\"theta_jn\"] = 0.93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802d038",
   "metadata": {},
   "source": [
    "Create the likelihood function for our analysis. The signal model is defined through the `waveform_generator` class, where we can set the approximant that will be used to reconstruct the signal. Then we pass this along with the priors defined above into a `GravitationalWaveTransient` likelihood.\n",
    "\n",
    "For this specific case, the likelihood is already marginalized over time and distance, so ultimately we search over chirp mass and mass ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb41ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_generator = bilby.gw.WaveformGenerator(\n",
    "    frequency_domain_source_model=bilby.gw.source.lal_binary_black_hole,\n",
    "    parameter_conversion=bilby.gw.conversion.convert_to_lal_binary_black_hole_parameters,\n",
    "    waveform_arguments={\"waveform_approximant\": \"IMRPhenomD\",\n",
    "                        \"reference_frequency\": 20, \n",
    "                        \"minimum_frequency\": flow})\n",
    "\n",
    "likelihood = bilby.gw.likelihood.GravitationalWaveTransient(\n",
    "    ifo_list, waveform_generator, priors=priors,\n",
    "    time_marginalization=True,\n",
    "    phase_marginalization=True,\n",
    "    distance_marginalization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089312ee",
   "metadata": {},
   "source": [
    "With everything set up, we can run the analysis. There is a helpful progress bar that you can monitor. In particular, take note of `dlogz`. This is an estimate of the total remaining evidence in the parameter space, which decreases (roughly) monotonically as the run progresses. The run terminates when `dlogz` drops below some threshold (default 0.1). The run will take about 2 hours to complete on your local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b709f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"GW190521_minimal\"\n",
    "label = \"GW190521_minimal\"\n",
    "bilby.core.utils.check_directory_exists_and_if_not_mkdir(outdir)\n",
    "\n",
    "result = bilby.run_sampler(\n",
    "    likelihood=likelihood, priors=priors,\n",
    "    outdir=outdir, label=label,\n",
    "    sampler=\"dynesty\", nlive=1000, check_point_delta_t=600, \n",
    "    check_point_plot=True, npool=1,\n",
    "    conversion_function=bilby.gw.conversion.generate_all_bbh_parameters,\n",
    "    result_class=bilby.gw.result.CBCResult)\n",
    "\n",
    "# Output plots\n",
    "result.plot_corner([\"chirp_mass\", \"mass_ratio\"])\n",
    "result.plot_waveform_posterior(interferometers=ifo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f668d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
